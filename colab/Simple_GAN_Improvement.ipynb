{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple GAN Improvement.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCQNkzATNJMN01r71ko6QQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/popescuaaa/playground/blob/master/Simple_GAN_Improvement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FsDYwBxTbwB"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJMPouaGXP22"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEHVEjHYWwBX"
      },
      "source": [
        "config = {\n",
        "  'learning_rate': 0.1,\n",
        "\n",
        "  'g': {\n",
        "      'dim_latent': 128, # z dimension for generator\n",
        "      'dim_hidden': 128, # size of the hidden layer\n",
        "  },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRSZV-U4Xtn9"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T76bkXbXwwW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WokFzgMXjiO"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3VbVBUMXjK-"
      },
      "source": [
        "# TODO: norm layer why ?\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    __module_list = [\n",
        "        nn.Linear(cfg['dim_latent'], cfg['dim_hidden']),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(cfg['dim_hidden'], cfg['dim_hidden'] * 2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(cfg['dim_hidden'] * 2,  28 * 28), # size of a mnist sample\n",
        "        nn.ReLU()\n",
        "    ]\n",
        "\n",
        "    # like a running container => in sequence\n",
        "    self.__net = nn.Sequential(*__module_list)\n",
        "\n",
        "  def forward(self, x):\n",
        "     return self.__net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51_YsZ26XnWr"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uTfdFRtXSjG"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, dim_input, dim_output):\n",
        "    super().__init__()\n",
        "    __module_list = [\n",
        "        nn.Linear(dim_input, dim_input // 2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(dim_input // 2, dim_input // 4),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(dim_input // 4, dim_output),\n",
        "        nn.Sigmoid() # Must be signmoid or smth that returns a vlue in [0, 1] to\n",
        "                    # make the BCELoss work\n",
        "    ]\n",
        "\n",
        "    self.__net = nn.Sequential(*__module_list)\n",
        "\n",
        "  def forward(self, x):\n",
        "     return self.__net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IcJF577Xypj"
      },
      "source": [
        "# System training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sSs2uzMBdhh"
      },
      "source": [
        "## Parameters and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjy2BL8EB4LE"
      },
      "source": [
        "env_learning_rate = config['learning_rate']\n",
        "\n",
        "g_cfg = config['g']\n",
        "\n",
        "g = Generator(g_cfg)\n",
        "d = Discriminator(28 * 28, 1) # we must generate a score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnWGsfUXNz1"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SskAyb4WX0lQ"
      },
      "source": [
        "batch_size = 32\n",
        "transforms = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]\n",
        ")\n",
        "\n",
        "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_raH-Q7BmB_"
      },
      "source": [
        "optimizer_G = optim.Adam(g.parameters(), lr=config['learning_rate'])\n",
        "optimizer_D = optim.Adam(d.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bmOh6tzxOp4"
      },
      "source": [
        "def trainD(real, noise):\n",
        "  fake_data = g(noise)\n",
        "  real_data = real\n",
        "  \n",
        "  d_real = d(real_data).view(-1)\n",
        "  d_fake = d(fake_data).view(-1)\n",
        "\n",
        "  loss_fake = criterion(d_fake, torch.zeros_like(d_fake))\n",
        "  loss_real = criterion(d_real, torch.ones_like(d_real))\n",
        "\n",
        "  loss = 0.5 * loss_fake + 0.5 * loss_fake\n",
        "  d.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer_D.step()\n",
        "\n",
        "  return loss\n",
        "\n",
        "def trainG(noise):\n",
        "  fake_data = g(noise)\n",
        "  output = d(fake_data).view(-1)\n",
        "\n",
        "  loss = criterion(output, torch.ones_like(output))\n",
        "  g.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer_G.step()\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "def train_system():\n",
        "  d_steps = 10\n",
        "  g_steps = 10\n",
        "\n",
        "  \n",
        "  #for _ in range(g_steps):\n",
        "  loss_g = trainG(noise)\n",
        "\n",
        "  #for _ in range(d_steps): \n",
        "  loss_d = trainD(real, noise)\n",
        "\n",
        "  return loss_d, loss_g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74RezgxaYgU7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wazi_QJaYfaM"
      },
      "source": [
        "num_epochs = 3\n",
        "torch.random.manual_seed(42)\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx, (real, _) in enumerate(loader):\n",
        "\n",
        "    real = real.view(-1, 784) # reshape -1 => don't know how many rows but should \n",
        "                              # be 784 columns\n",
        "    batch_size = real.shape[0]\n",
        "\n",
        "    ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
        "    noise = torch.randn(batch_size, config['g']['dim_latent'])\n",
        "    \n",
        "    lossD, lossG = train_system()\n",
        "\n",
        "    if batch_idx == 500:\n",
        "\n",
        "        print(\n",
        "            f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
        "                  Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFHxJbYFgJtK"
      },
      "source": [
        "## Result\n",
        "\n",
        "\n",
        "```\n",
        "Epoch [0/10] Batch 0/1875                   Loss D: 0.6815, loss G: 0.0000\n",
        "Epoch [1/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "Epoch [2/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "Epoch [3/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "Epoch [4/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "Epoch [5/10] Batch 0/1875                   Loss D: 50.0000, loss G: 0.0000\n",
        "```\n",
        "\n",
        "The 1/2 = 50% is the convergence value for D and because we have loss at this value at epoch two the G can't learn properly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pybx6lqPa_9i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}